{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4fa897-4fce-4dfc-a01c-0a026fded6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\victo\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: anthropic in c:\\users\\victo\\anaconda3\\lib\\site-packages (0.40.0)\n",
      "Requirement already satisfied: openai in c:\\users\\victo\\anaconda3\\lib\\site-packages (1.57.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from anthropic) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from anthropic) (0.28.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from anthropic) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from anthropic) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\victo\\anaconda3\\lib\\site-packages (from anthropic) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from anthropic) (4.11.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\victo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\victo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\victo\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\victo\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2 anthropic openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7865834f-0efc-44ff-a4c4-3fdade421707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext, filedialog, messagebox\n",
    "import PyPDF2\n",
    "from anthropic import Anthropic\n",
    "import openai\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuração das APIs\n",
    "OPENAI_API_KEY = \"\"\n",
    "CLAUDE_API_KEY = \"\"\n",
    "\n",
    "class PDFAnalyzerApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Analisador de PDF - OpenAI vs Claude\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "        \n",
    "             \n",
    "        # Variáveis de controle\n",
    "        self.pdf_content = \"\"\n",
    "        self.selected_openai_model = tk.StringVar(value=\"gpt-4\")\n",
    "        self.selected_claude_model = tk.StringVar(value=\"claude-v1\")\n",
    "\n",
    "        # Inicializar clientes API\n",
    "        self.setup_api_clients()\n",
    "\n",
    "        # Interface principal\n",
    "        self.setup_ui()\n",
    "        \n",
    "    def setup_api_clients(self):\n",
    "        try:\n",
    "            self.openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "            self.anthropic = Anthropic(api_key=CLAUDE_API_KEY)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erro\", f\"Erro ao inicializar APIs: {str(e)}\")\n",
    "            raise SystemExit\n",
    "        \n",
    "    def setup_ui(self):\n",
    "        # Frame para seleção e processamento do PDF\n",
    "        input_frame = ttk.LabelFrame(self.root, text=\"Entrada\", padding=10)\n",
    "        input_frame.pack(fill=\"x\", padx=10, pady=5)\n",
    "        \n",
    "        # Área para seleção do PDF\n",
    "        pdf_frame = ttk.Frame(input_frame)\n",
    "        pdf_frame.pack(fill=\"x\", pady=5)\n",
    "        \n",
    "        self.pdf_path = ttk.Entry(pdf_frame, width=80)\n",
    "        self.pdf_path.pack(side=\"left\", padx=5)\n",
    "        \n",
    "        ttk.Button(pdf_frame, text=\"Selecionar PDF\", command=self.select_pdf).pack(side=\"left\", padx=5)\n",
    "        ttk.Button(pdf_frame, text=\"Processar PDF\", command=self.process_pdf).pack(side=\"left\", padx=5)\n",
    "        \n",
    "        # Frame para prompts\n",
    "        prompts_frame = ttk.Frame(input_frame)\n",
    "        prompts_frame.pack(fill=\"x\", pady=5)\n",
    "        \n",
    "        ttk.Label(prompts_frame, text=\"Prompt de Análise:\").pack(anchor=\"w\")\n",
    "        self.analysis_prompt = scrolledtext.ScrolledText(prompts_frame, height=3)\n",
    "        self.analysis_prompt.pack(fill=\"x\", pady=5)\n",
    "        self.analysis_prompt.insert(\"1.0\", \"\"\"Elabore um relatório de sentença de mérito trabalhista, estruturado em formato narrativo e com redação objetiva, sempre utilizando as abreviações \"rte.\" e \"rda.\" sem mencionar o nome das partes. No relatório da rda., utilize sempre a construção \"que o rte. não trabalhou em sobrejornada; que o rte. não faz jus a ...\". Comece sempre com \"O(a) rte. pede ...tal tal tal\". Não cite pedidos referentes a honorários e justiça gratuita em geral. A fundamentação deve incluir o título do tópico \"Das horas extras\". Siga o seguinte padrão: inicie apresentando as alegações do autor sobre os fatos e pedidos formulados, começando com \"O(a) rte. pede...\", em seguida exponha de forma contínua as impugnações e argumentos apresentados pela defesa da reclamada, utilizando as abreviações \"rte.\" e \"rda.\" sem mencionar o nome das partes. Não analise o mérito dos pedidos nem julgue o processo. O texto não deve utilizar listas, tópicos ou subdivisões. Deve ser fluido, técnico e redigido em terceira pessoa, com linguagem clara e direta, mantendo o tom impessoal e a formalidade típica de decisões judiciais trabalhistas. Evite qualquer tipo de análise ou opinião, limitando-se à descrição dos fatos e alegações conforme os autos.\"\"\")\n",
    "        \n",
    "        ttk.Label(prompts_frame, text=\"Prompt de Comparação:\").pack(anchor=\"w\")\n",
    "        self.comparison_prompt = scrolledtext.ScrolledText(prompts_frame, height=3)\n",
    "        self.comparison_prompt.pack(fill=\"x\", pady=5)\n",
    "        self.comparison_prompt.insert(\"1.0\", \"Você é um juiz de direito especializado em análise de processos trabalhistas. Sua tarefa é analisar e comparar dois resumos gerados por diferentes sistemas de inteligência artificial sobre um processo trabalhista e compará-los ao processo principal. O objetivo é garantir que todas as informações importantes estejam presentes, identificar lacunas e avaliar qual resumo é mais completo e fiel ao processo. Você receberá dois resumos do processo trabalhista, além de informações do processo principal, quando fornecidas. Sua análise deve seguir os seguintes passos: Primeiro, compare os dois resumos, identificando as informações que aparecem em ambos, as que aparecem apenas no primeiro resumo e as que aparecem apenas no segundo. Em seguida, compare os resumos com o processo principal para verificar se todas as informações importantes do processo estão presentes em pelo menos um dos resumos e se há informações nos resumos que não constam no processo principal. Identifique quaisquer fatos essenciais que estejam ausentes em ambos os resumos. Por fim, forneça uma avaliação geral da qualidade e completude dos resumos em relação ao processo principal, indicando qual dos resumos é mais completo e fiel. Certifique-se de ser claro, objetivo e detalhado em sua análise, focando nas informações mais relevantes do processo trabalhista e destacando qualquer falha significativa ou omissão.\")\n",
    "\n",
    "        ttk.Label(prompts_frame, text=\"Prompt de Análise Híbrida:\").pack(anchor=\"w\")\n",
    "        self.hybrid_prompt = scrolledtext.ScrolledText(prompts_frame, height=3)\n",
    "        self.hybrid_prompt.pack(fill=\"x\", pady=5)\n",
    "        self.hybrid_prompt.insert(\"1.0\", \"Una dois resumos e crie um texto único com as informações deles, sem redundância, em um texto coeso, conciso e formal, estruturado com parágrafos bem definidos, linguagem técnica e impessoal, sem listas ou bullets, como em decisões judiciais trabalhistas, com clareza e precisão. Sempre utilize as abreviações rte. e rda., omitindo o nome da parte. No relatório da rda., empregue sempre a construção 'que o rte. não trabalhou em sobrejornada; que o rte. não faz jus a ...'. Inicie sempre com 'O(a) rte. pede ... tal tal tal'. Não mencione pedidos referentes a honorários e justiça gratuita em geral. Na fundamentação, inclua o título dos tópicos, por exemplo, 'Das horas extras'.\")\n",
    "\n",
    "        ttk.Label(prompts_frame, text=\"Prompt Customizado:\").pack(anchor=\"w\")\n",
    "        self.custom_prompt = scrolledtext.ScrolledText(prompts_frame, height=3)\n",
    "        self.custom_prompt.pack(fill=\"x\", pady=5)\n",
    "        self.custom_prompt.insert(\"1.0\", \"Insira seu prompt personalizado aqui...\")\n",
    "\n",
    "        # Frame para seleção de modelos\n",
    "        model_frame = ttk.LabelFrame(input_frame, text=\"OpenAI\", padding=10)\n",
    "        model_frame.pack(side=\"left\", padx=5, pady=5)\n",
    "        openai_models = [\"gpt-4o\", \"gpt-4o-mini\", \"o1-mini\"]\n",
    "        self.create_model_selection(model_frame, \"Modelo OpenAI:\", openai_models, self.selected_openai_model)\n",
    "        model_frame = ttk.LabelFrame(input_frame, text=\"Claude\", padding=10)\n",
    "        model_frame.pack(side=\"left\", padx=5, pady=5)\n",
    "        claude_models = [\"claude-3-5-sonnet-latest\", \"claude-3-5-haiku-latest\", \"claude-3-opus-latest\"]\n",
    "        self.create_model_selection(model_frame, \"Modelo Claude:\", claude_models, self.selected_claude_model)\n",
    "\n",
    "        # Frame para ações\n",
    "        actions_frame = ttk.Frame(self.root)\n",
    "        actions_frame.pack(fill=\"x\", padx=10, pady=5)\n",
    "        \n",
    "        ttk.Button(actions_frame, text=\"Comparar Resultados\", command=self.compare_results).pack(side=\"left\", padx=5)\n",
    "        ttk.Button(actions_frame, text=\"Salvar Resultados\", command=self.save_results).pack(side=\"left\", padx=5)\n",
    "        ttk.Button(actions_frame, text=\"Gerar Resumo Híbrido\", command=self.generate_hybrid).pack(side=\"left\", padx=5)\n",
    "        ttk.Button(actions_frame, text=\"Processar Prompt Customizado\", command=self.process_custom_prompt).pack(side=\"left\", padx=5)\n",
    "        \n",
    "       # Barra de progresso\n",
    "        self.progress_var = tk.DoubleVar()\n",
    "        self.progress_bar = ttk.Progressbar(self.root, variable=self.progress_var, maximum=100)\n",
    "        self.progress_bar.pack(fill=\"x\", padx=10, pady=5)\n",
    "\n",
    "        # Notebook para resultados\n",
    "        results_frame = ttk.LabelFrame(self.root, text=\"Resultados\", padding=10)\n",
    "        results_frame.pack(fill=\"both\", expand=True, padx=10, pady=5)\n",
    "\n",
    "        self.notebook = ttk.Notebook(results_frame)\n",
    "        self.notebook.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        # Abas para resultados\n",
    "        openai_tab = ttk.Frame(self.notebook)\n",
    "        claude_tab = ttk.Frame(self.notebook)\n",
    "        comparison_tab = ttk.Frame(self.notebook)\n",
    "        hybrid_tab = ttk.Frame(self.notebook)\n",
    "        custom_tab = ttk.Frame(self.notebook)\n",
    "        \n",
    "        self.notebook.add(openai_tab, text=\"OpenAI\")\n",
    "        self.notebook.add(claude_tab, text=\"Claude\")\n",
    "        self.notebook.add(comparison_tab, text=\"Comparação\")\n",
    "        self.notebook.add(hybrid_tab, text=\"Resumo Híbrido\")\n",
    "        self.notebook.add(custom_tab, text=\"Análise Customizada\")\n",
    "        \n",
    "        self.openai_result = scrolledtext.ScrolledText(openai_tab)\n",
    "        self.claude_result = scrolledtext.ScrolledText(claude_tab)\n",
    "        self.comparison_result = scrolledtext.ScrolledText(comparison_tab)\n",
    "        self.hybrid_result = scrolledtext.ScrolledText(hybrid_tab)\n",
    "        self.custom_result = scrolledtext.ScrolledText(custom_tab)\n",
    "        \n",
    "        self.openai_result.pack(fill=\"both\", expand=True)\n",
    "        self.claude_result.pack(fill=\"both\", expand=True)\n",
    "        self.comparison_result.pack(fill=\"both\", expand=True)\n",
    "        self.hybrid_result.pack(fill=\"both\", expand=True)\n",
    "        self.custom_result.pack(fill=\"both\", expand=True)\n",
    "        \n",
    "        \n",
    "    def create_model_selection(self, frame, label_text, options, var):\n",
    "        ttk.Label(frame, text=label_text).pack(anchor=\"w\")\n",
    "        for option in options:\n",
    "            ttk.Radiobutton(frame, text=option, value=option, variable=var).pack(anchor=\"w\")\n",
    "        \n",
    "    def select_pdf(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"PDF files\", \"*.pdf\")])\n",
    "        if file_path:\n",
    "            self.pdf_path.delete(0, tk.END)\n",
    "            self.pdf_path.insert(0, file_path)\n",
    "    \n",
    "    def process_pdf(self):\n",
    "        if not self.pdf_path.get():\n",
    "            messagebox.showerror(\"Erro\", \"Selecione um PDF primeiro!\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Extrair texto do PDF\n",
    "            self.progress_var.set(10)\n",
    "            self.root.update_idletasks()\n",
    "            \n",
    "            with open(self.pdf_path.get(), 'rb') as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                self.pdf_content = \"\"\n",
    "                total_pages = len(reader.pages)\n",
    "                \n",
    "                for i, page in enumerate(reader.pages):\n",
    "                    self.pdf_content += page.extract_text()\n",
    "                    self.progress_var.set(10 + (i + 1) / total_pages * 30)\n",
    "                    self.root.update_idletasks()\n",
    "            \n",
    "            if not self.pdf_content.strip():\n",
    "                raise Exception(\"PDF vazio ou ilegível\")\n",
    "            \n",
    "            # Análise com OpenAI\n",
    "            self.progress_var.set(40)\n",
    "            self.root.update_idletasks()\n",
    "            \n",
    "            analysis_prompt = self.analysis_prompt.get(\"1.0\", tk.END).strip()\n",
    "            openai_response = self.openai_client.chat.completions.create(\n",
    "                model=self.selected_openai_model.get(),\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Você é um assistente especializado em análise de documentos.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"{analysis_prompt}\\n\\nDocumento:\\n{self.pdf_content}\"}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            self.openai_result.delete(\"1.0\", tk.END)\n",
    "            self.openai_result.insert(\"1.0\", openai_response.choices[0].message.content)\n",
    "            \n",
    "            # Análise com Claude\n",
    "            self.progress_var.set(70)\n",
    "            self.root.update_idletasks()\n",
    "            \n",
    "            \n",
    "            claude_response = self.anthropic.messages.create(\n",
    "                model=self.selected_claude_model.get(),\n",
    "                max_tokens=4096,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": f\"{analysis_prompt}\\n\\nDocumento:\\n{self.pdf_content}\"}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            self.claude_result.delete(\"1.0\", tk.END)\n",
    "            self.claude_result.insert(\"1.0\", claude_response.content[0].text)\n",
    "            \n",
    "            self.progress_var.set(100)\n",
    "            messagebox.showinfo(\"Sucesso\", \"PDF processado com sucesso!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.progress_var.set(0)\n",
    "            messagebox.showerror(\"Erro\", f\"Erro ao processar PDF: {str(e)}\")\n",
    "\n",
    "    def generate_hybrid(self):\n",
    "        if not self.openai_result.get(\"1.0\", tk.END).strip() or not self.claude_result.get(\"1.0\", tk.END).strip():\n",
    "            messagebox.showerror(\"Erro\", \"Processe o PDF e gere os resumos primeiro!\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            hybrid_prompt = self.hybrid_prompt.get(\"1.0\", tk.END).strip()\n",
    "            openai_text = self.openai_result.get(\"1.0\", tk.END).strip()\n",
    "            claude_text = self.claude_result.get(\"1.0\", tk.END).strip()\n",
    "            \n",
    "            prompt_with_summaries = f\"\"\"\n",
    "            Análise Comparativa de Resumos Processuais\n",
    "\n",
    "            RESUMO OPENAI:\n",
    "            {openai_text}\n",
    "\n",
    "            RESUMO CLAUDE:\n",
    "            {claude_text}\n",
    "\n",
    "            DIRETRIZES PARA ANÁLISE SINTÉTICA:\n",
    "            {hybrid_prompt}\n",
    "            \"\"\"\n",
    "            \n",
    "            hybrid_response = self.openai_client.chat.completions.create(\n",
    "                model=self.selected_openai_model.get(),\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Você é um assistente especializado em análise de documentos.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_with_summaries}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            self.hybrid_result.delete(\"1.0\", tk.END)\n",
    "            self.hybrid_result.insert(\"1.0\", hybrid_response.choices[0].message.content)\n",
    "            \n",
    "            self.progress_var.set(100)\n",
    "            self.notebook.select(3)\n",
    "            messagebox.showinfo(\"Sucesso\", \"Resumo híbrido gerado com sucesso!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.progress_var.set(0)\n",
    "            messagebox.showerror(\"Erro\", f\"Erro ao gerar resumo híbrido: {str(e)}\")\n",
    "    \n",
    "    def compare_results(self):\n",
    "        if not self.openai_result.get(\"1.0\", tk.END).strip() or not self.claude_result.get(\"1.0\", tk.END).strip():\n",
    "            messagebox.showerror(\"Erro\", \"Processe o PDF primeiro!\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            self.progress_var.set(50)\n",
    "            comparison_prompt = self.comparison_prompt.get(\"1.0\", tk.END).strip()\n",
    "            openai_text = self.openai_result.get(\"1.0\", tk.END).strip()\n",
    "            claude_text = self.claude_result.get(\"1.0\", tk.END).strip()\n",
    "            \n",
    "            comparison_response = self.anthropic.messages.create(\n",
    "                model=self.selected_claude_model.get(),\n",
    "                max_tokens=4096,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": f\"{comparison_prompt}\\n\\nDocumento Original:\\n{self.pdf_content}\\n\\nResultado OpenAI:\\n{openai_text}\\n\\nResultado Claude:\\n{claude_text}\"}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            self.comparison_result.delete(\"1.0\", tk.END)\n",
    "            self.comparison_result.insert(\"1.0\", comparison_response.content[0].text)\n",
    "            \n",
    "            self.progress_var.set(100)\n",
    "            self.notebook.select(2)\n",
    "            messagebox.showinfo(\"Sucesso\", \"Comparação concluída!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.progress_var.set(0)\n",
    "            messagebox.showerror(\"Erro\", f\"Erro na comparação: {str(e)}\")\n",
    "\n",
    "    def process_custom_prompt(self):\n",
    "        try:\n",
    "            self.progress_var.set(30)\n",
    "            custom_prompt = self.custom_prompt.get(\"1.0\", tk.END).strip()\n",
    "        \n",
    "            if not custom_prompt or custom_prompt == \"Insira seu prompt personalizado aqui...\":\n",
    "                messagebox.showerror(\"Erro\", \"Insira um prompt válido!\")\n",
    "                return\n",
    "            \n",
    "                self.progress_var.set(50)\n",
    "                custom_response = self.openai_client.chat.completions.create(\n",
    "                    model=self.selected_openai_model.get(),\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"Você é um assistente especializado em análise de documentos.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"{custom_prompt}\\n\\nDocumento:\\n{self.pdf_content}\"}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "            self.custom_result.delete(\"1.0\", tk.END)\n",
    "            self.custom_result.insert(\"1.0\", custom_response.choices[0].message.content)\n",
    "                \n",
    "            self.progress_var.set(100)\n",
    "            self.notebook.select(4)\n",
    "            messagebox.showinfo(\"Sucesso\", \"Análise customizada concluída!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "                self.progress_var.set(0)\n",
    "                messagebox.showerror(\"Erro\", f\"Erro ao processar prompt customizado: {str(e)}\")\n",
    "            \n",
    "\n",
    "    def save_results(self):\n",
    "        if not self.comparison_result.get(\"1.0\", tk.END).strip():\n",
    "            messagebox.showerror(\"Erro\", \"Não há resultados para salvar!\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            results = {\n",
    "                \"pdf_path\": self.pdf_path.get(),\n",
    "                \"analysis_prompt\": self.analysis_prompt.get(\"1.0\", tk.END).strip(),\n",
    "                \"comparison_prompt\": self.comparison_prompt.get(\"1.0\", tk.END).strip(),\n",
    "                \"openai_result\": self.openai_result.get(\"1.0\", tk.END).strip(),\n",
    "                \"claude_result\": self.claude_result.get(\"1.0\", tk.END).strip(),\n",
    "                \"comparison_result\": self.comparison_result.get(\"1.0\", tk.END).strip(),\n",
    "                \"hybrid_result\": self.hybrid_result.get(\"1.0\", tk.END).strip(),\n",
    "                \"custom_prompt\": self.custom_prompt.get(\"1.0\", tk.END).strip(),\n",
    "                \"custom_result\": self.custom_result.get(\"1.0\", tk.END).strip(),\n",
    "                \"timestamp\": timestamp\n",
    "            }\n",
    "            \n",
    "            file_path = filedialog.asksaveasfilename(\n",
    "                defaultextension=\".json\",\n",
    "                filetypes=[(\"JSON files\", \"*.json\")],\n",
    "                initialfile=f\"analise_pdf_{timestamp}.json\"\n",
    "            )\n",
    "            \n",
    "            if file_path:\n",
    "                with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "                messagebox.showinfo(\"Sucesso\", \"Resultados salvos com sucesso!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erro\", f\"Erro ao salvar resultados: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = PDFAnalyzerApp(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
